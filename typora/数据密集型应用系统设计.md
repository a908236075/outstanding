## 第一部分 数据系统的基石

### 第一章 可靠性 可扩展性 可维护性

1. **数据密集型**应用主要的挑战是是数据,**计算密集型**主要的挑战是cup处理速度.
2. **可靠性**是指即使系统发生了故障,程序依然可以工作和运行.针对可靠性介绍了几种类型的故障:**硬件故障,软件错误,人为错误.**
3. **可扩展性**:因为无法承受的负载所以才有可扩展性的需求,如何描述负载是一个问题.
4. Twitter处理用户发布后,他的订阅者能够查看到推文的办法是对于普通的用户,直接通过就关键字进行查找,而拥有百万粉丝的人,缓存订阅者列表,进行遍历,将消息加入到用户的时间线中,这样用户只要直接访问时间线就可以了.
5. 描述负载:负载可以用称为负载参数的若干数字来描述。参数的最佳选择取决于系统的体系结构，它可能是Web服务器的每秒请求处理次数，数据库中写入的比例 ,聊天室的同时活动用户数量， 缓存命中率等。 有时平均值很重要 ，有时系统瓶颈来自于少数峰值 .
6. 响应时间包括延时和处理请求的时间.
7. 影响请求响应时间的因素:大多数请求是相当快的，但偶尔会有异常表示需要更长的时间 。 也许这些异常请求确实代价很高，例如它们的数据大很多。但有时，即使所有请求都相罔，也会由于其他变量因素而引入一些随机延迟抖动，这些因素包括上下文切换和进程调度、网络数据包丢失和TCP重传、垃圾回收暂停、缺页中断和磁盘I/O ，甚至服务器机架的机械振动.
8. 亚马逊还注意到，响应时间每增加100ms ，销售额就会下降了约 1 % ，其他研究则表明， 1s的延迟增加等价于客户满意度下降 16%。  

### 第二章 数据模型与查询语言

1. 关系型数据库需要与业务代码进行属性的对应,例如表对用对象,行则对应属性,这种转换会感到十分的笨重,NoSql具有更加灵活的方式,所以一些场景更加的适合.
2. 关系数据库和文档数据库:文档数据库更像json一样将对象的所有的信息展示出来,应用处理更加的方便.但关系型数据库更适合存储有**级联操作**的数据.
3. 数据更改时,文档数据只需要用新的字段编写并处理之前旧的字段,而关系型数据库则需要用alert语句,更改数据 的字段.关系数据这种操作很费事.
4. 命令式查询语言和声明式查询语言.命令式以特定的顺序执行某些操作,而声明式只需要指定需要什么数据以及满足什么条件.声明式调用API,隐藏了实现的细节.
5. 各种不同的数据模型.其中文档数据模型尽量不展示对象之间的关系,而图数据模型尽量用来展示对象之间的关系.

### 第三章 数据存储与检索

1. 索引:它们背后的基本原理都是保留一些额外的元数据，这些元数据作为路标，帮助定位想要的数据。
2. Hash索引：索引里面记录了value每一行的地址，检索的时候可以快速定位。
   1. 劣势:需要将所有的索引放入到内存中,且范围查询不友好.
3. SSTable:每个日志结构的存储段都是一组k巳 y-value对的序列。这些 key-valu 巳对按
   照它们的写入 成员序排列，并且对于出现在 日志中的同一个键，后出现的值优于之前的值。除此之外，文件中 key-value对的顺序并不重要。这种格式称为**排序字符串表**，或简称为SSTable 
   1. SSTable优点:
      - 合并段更加的简单高效,   进行排序的过程中可以把重复的键舍弃掉.
      - 查找键时,不需要遍历所有的键,应为是排序的,可以根据内存中现有的键进行推断.
   2. SSTable的压缩方式：在**大小分级**的压缩中，较新的和较小的SSTa bl es被连续合并到较旧和较大的SSTa bl es。在**分层压缩**中，键的范围分裂成多个更小的SSTa ble s ，旧数据被移动到单独的“层级”，这样压缩可以逐步进行并节省磁盘空间。  
4. B-trees:
5. 事务处理与分析处理
6. 传输过程使用二进制就可以,为什么还需要有有json和xml这种格式?
   - 由于**内存布局不同**,不同的语言平台相同的对象可能有不同的表现形式,而且除了c语言之外,其它的语言操作内存并不是非常的方便,而json和xml是**独立于语言平台之外**的,而且具有非常好的**可读性**,对于大部分平台,不是十分追求传输性能的系统,非常的适合.
7. JSON,XML,CSV使用最为广泛的文本格式.

## 第二部分 分布式数据结构

### 第五章 数据复制

1. **共享内存架构和共享磁盘架构**:内存架构的可扩展性不强,性能不具有线性增长,仍局限于某个特定的地理位置，无主提供异地容错能力。  
2. **无共享架构**:运行数据软件的机器或者虚拟机被称为节点,每个节点独立使用本地cup,内存和磁盘,通信通过网络来实现,是广泛应用的模式.
3. 数据复制(数据分布在多个节点):多台机器复制相同的数据,一个副部失效其它可以接替使服务继续运行.
4. **复制数据的三种方法**:主从复制,多主节点复制和无主节点复制.
5. 通过复制想要达到的**目的**:
   - 使数据在地理位置上更接近用户，从而降低访问延迟 。
   - 当部分组件出现位障，系统依然可以继续工作，从而提高可用性。
   - 扩展至多台机器以同时提供数据访问服务，从而提高**读吞吐量**。  
6. 多个副本,怎么保证数据一致性
   1. 指定某一个副本为主副本 （或称为主节点） 。当客户写数据库时，必须将写请求 首先发送给主副本,主副本首先将新数据写入本地存储。
   2. 其他副本则全部称为从副本（或称为从节点).主副本把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从副本。每个从副本获得更改日志之后将其应用到本地，且严格保持与主副本相同的**写入顺序**。
   3. 客户端从数据库中读数据时 ，可以在主副本或者从副本上执行查询。再次强调，**只有主副本才可以接受写请求** ：从客户端的角度来看，**从副本都是只读的**。
7. 创建新的节点:从节点会复制主节点的数据,在复制的时候,主节点会记录在此期间影响数据一致性的日志,待从节点复制完成,同步日志.
8. 从节点失效:当从节点能顺利重启,例如遇到暂时的网络中断,从节点会磁盘会记录事务日志,恢复到崩溃之前的最后一条日志.
9. 分布式系统核心的基本问题:节点失效、网络不可靠、副本一致性、持久性、可用性与延迟之间各种细微的权衡，实际上正是分布式系统核心的基本问题。
10. 复制日志的实现:
   1. 基于语句的复制:将增删改的日志进行记录,同步从节点.但是例如使用now()函数会出现问题.需要进行转换.
   2. 预写日志:同步的是磁盘引擎的数据结果.记录了哪些磁盘块的那些字节改变.
   3. 行逻辑日志:记录行级别的日志.与存储逻辑剥离.
   4. 基于触发器:不是由数据库实现的而是通过软件实现,应对只需要复制部分数据的需求.
11. 复制滞后问题
    1. 读写一致性:
       - 即读取的数据优先从自己写的地方读取.优先从主节点读取数据.此种情况适用于例如用户编辑自己的材料,而多人多可编辑的东西就不适合,是系统丧失了可扩展性.主节点可是设置一个时间戳,等待所有从节点都同步后才允许提供读的服务.
       - 如果读取的信息不再同一个设备例如web端和移动端,必须要保证他们的数据中心是一致的.
    2. 单调读:确保用户读取的数据从**同一个副本**进行读取,避免了因为数据不同步导致之前读到的信息在第二次请求的时候消失了.
    3. 前缀一致读:保证消息的顺序.
    4. 多主节点适用的场景:多数据中心,离线客户端操作,协作编辑.
    5. 多主节点处理写冲突:指定特定的主节点进行写操作.
       1. 收敛一致状态一般的解决方法是写操作设置时间戳,或者给从节点设置**编号编号大的优先**执行,但是都会有丢失数据的风险.
       2. 自定义冲突解决逻辑:在应用层解决,写入读取日志的时候监测冲突并处理.读取时候将所有节点的值都读到比较处理冲突.
    6. 无主节点复制:客户端**读取数据**的时候,可能会读取失效的数据,需要根据**版本号**进行排查,保证数据的一致性.也可以通过数值进行比较,如果一个节点返回的数值不同,则这个节点的数据存入有误.
    7. 无主节点的写:无法解决并发写问题,可以自定义他们的顺序,将时间戳最大的进行舍弃,,可能会有数据丢失的风险.也可以通过版本号来区分,客户端需要合并旧值.不会发生消息丢失.

### 第六章 数据分区

1. 面对一些海量数据或非常高的查询压力,复制技术还不够,我们需要将数据拆分成分区,也称为分片.
2. 键-值数据的分区:
   1. 想让数据尽可能均匀的分配到多个节点上,提高读写吞吐量.
   2. 基于关键字区间分区:
      - 难点 数据本来就不均匀.例如按字母分区,有些字母的数据非常的多.
      - 直接用时间戳进行排序,会导致写入数据的时候,都集中在一个节点,一般会以设备名称作为前缀.
   3. 基于关键字哈希值分区
      - 根据hash范围进行分区,但要丧失区间查询特性.
      - 做一个折中的方案,可以声明由多个列组成的复合主键,复合主键只有第一部分可以用于hash分区,其它的部分用作组合索引对表中的数据进行排序.
   4. 负载倾斜与热点
      - 如果消息都是相同的关键字,即使用了hash算法,还是会导致数据集中在一个节点上.
      - 解决办法是在这类特殊的关键字上加上一个随机数.
   5. 分区与二级索引
      1. 二级索引带来的主要挑战是它们不能规整的地映射到分区中。有两种主要的方法来支持对二级索引进行分区：基于文档的分区和基于词条的分区。 
      2. **基于文档的分区**:每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中数据,构建的是**本地索引**。缺点是想要建立的二级索引可能不会在同一个分区上,需要用户自己构建合理的分区方案.
      3. **基于词条的二级索引**:对所有的数据构建**全局索引**.但是索引必须分区.但是创建的时候非常的复杂.所有的数据库都不支持**更新**二级索引.
   6. 分区在平衡
      1. 查询压力增加,数据规模增加,节点出现故障都需要分区在平衡.
      2. 固定数量的分区:创建远超实际节点数的分区数，然后为每个节点分配多个分区。如果添加新的节点,就从冗余的分区数中匀一个,这样并不会改变关键字到分区的映射关系.
   7. 动态分区
      1. 根据数据动态的进行分区或者进行分区的合并.如果没有达到分区条件,导致总是一个分区进行服务,可以通过预分裂进行优化.
   8. 请求路由
      1. 当客户端获取数据的时候,多个节点会进行跳转,最终找到数据.一般会使用zookeeper,处理协同类的信息.节点发生的变化,也会第一时间同步到zookeeper中.

### 第七章 事务

1. 事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元。要么都成功,要么多失败.
2. 事务的ACID中,**C一致性**是需要应用层去保障的,而其余的特性才是数据库自身的属性.
3. 多对象事务的必要性:因为会出现跨分区操作,多对象事务实现非常困难.除了分区,当设计系统多部分的更改属性的时候还是需要保证多对象的事物.例如:关系数据模型,有些值的更改对其它数据有影响,不能只执行部分的操作.
4. 重试中止的事物虽然是简单有效的错误处理机制,但它并不完美:
   - 如果数据操作部分已经成功,只是返回客户端的时候进行了错误的提示,这回导致操作的重复.
   - 如果错误由系统超负荷导致,重试只会加剧错误.
   - 出现了永久性故障,重试毫无意义.
   - 如果事务有其它副作用,例如发送一封邮件,会带来不好的体验.
5. 防止脏读,并没有采用读锁的机制,因为运行时间较长的写事务可能会导致读取的等待时间太长.一般的解决方法是维护更新的两个版本,如果事务提交成功就返回新值给读,如果提交失败了,就返回旧值.
6. 实现快照隔离级别写锁不会阻止读的进行,这使读的性能有大的提升,考虑到**多个**正在进行的事务可能会在不同的时间点查看数据库状态,所以数据库保留了多个不同的提交版本,叫做**多版本并发控制(MVCC).**
7. 写倾斜和数据丢失:如果两个事务读取相同的一组对象，然后更新其中 一部分:不同的事务可能更新不同的对象，则可能发生写倾斜 ;而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失 .
8. 串行化:严格按照串行顺序执行(实际串行执行),两阶段锁和乐观并发控制技术.
9. 实际串行执行:即在一个线程上按顺序方式每次只执行一个事务 .
   - Redis就采用了这种方式.避免了锁开销和内存切换.
   - 不支持交互式的多语句事务(即下一个数据处理需要等待上一次处理的结果).将所有的数据加载到内存中.
   - 写入吞吐量必须足够低,才能在单个cpu核上处理,否则采用分区技术,最好没有跨区的事物.
   - 跨区事物也可以支持,但占比需要非常的小.
10. 两阶段加锁:只有这一种串行化算法被数据库广泛使用.第一阶段事务执行需要获取锁,第二阶段事务执行结束则释放锁.两阶段加锁名称的由来.
11. 基本用法:
    1. 事务想要读取对象,必须先以共享的模式获得锁.可以有多个事务同时获得一个对象的共享锁.
    2. 如果事务想要修改对象必须以独占模式获取锁.如果该对象已经被加锁,则修改的事务必须等待.
    3. 如果事务首先读取对象,然后尝试写入对象,必须将共享锁升级为独占锁.
12. 谓词锁:作用类似于共享或者独占锁,区别在于它并不属于某个特定的对象,而是作用于满足某些搜索条件的所有查询对象.
13. 索引区间锁:由于谓词锁性能不佳,光检查锁就很耗费资源,索引我们大部分情况下使用的是索引区间锁.索引区间锁对谓词锁做了粗话,使它的性能得到了提升.
14. 可串行化的快照隔离
    1. 是一种乐观并发控制.常采用多版本并发控制技术(MVCC)来实现.
    2. 当读取数据的时候,会忽略那些在创建快照时尚未提交事务的写入.
    3. 当事务提交的时候,会检查是否当时忽略的事务已经完成了提交,如果是就中止当前的事务.在写入数据的时候,会拿旧值进行比较,如有有更改说明存在事务的竞争,终止当前的操作.

### 第八章 分布式系统的挑战

1. 同步与异步网络
   1. 电路非常适合音频或视频通话，通话期间只需每秒传送固定数量的数据。而TCP连接的数据包则会尝试使用所有可用的网络带宽。 TCP可以传送任意大小可变的数据块（例如电子邮件或网页），它会尽力
      在最短的时间内完成数据发送。而当 TCP连接空闲时，通常不占用任何带宽出。  
2. 由于节点的状态很难由**自身的状态**来判断，所以一般系统会使用多节点同时确认，如果多数认为节点失效，则改节点就被标记为失效的状态。
3. Fencing（栅栏）令牌:
   1. 每次锁服务在授予锁或者租约时,还会同时返回一个fencing令牌,该令牌每次授予一次都会递增一次.要求客户端每次向存储系统发送写请求时,都必须包含所持有的fencing令牌.存储系统会监测版本号,如果发送来的令牌小于系统的令牌,则拒绝执行.
   2. Zookeeper作为锁服务时候,可以使用事务标识zxid或者节点版本号cversion来充当fencing令牌.
4. 拜占庭故障
   1. 某个系统中即使发生部分节点故障，甚至不遵从协议，或者恶意攻击 、 干扰网络，但仍可继续正常运行，那么我们称之为拜占庭式容错系统.

### 第九章 一致性与共识

1. 可线性化
   1. 使系统看起来好像只有一个数据副本.
2. 可线性化与可串行化的区别:
   1. **可串行化**:是事务的隔离属性,其中每个事务可以读写**多个对象**,保证事务的执行结果和串行执行(即每次执行一个事务)的结果完全相同.
   2. **可线性化**:是读写寄存器(**单个对象**)的最新值保证,并不要求将操作组合到事务中去,也无法解决幻读的问题.
3. 兰伯特时间戳(lamport):保证节点间的因果关系,生成节点的最大计数器,如果节点接受到的请求中,最大计数器大于版本的自身内嵌的,则节点处理请求后将版本改为该值,以后只接受比此值大的版本.
4. 分布式事务与共识
   1. 多节点事务需要有一个**协调者**,协调者会管理所有的节点的事物,协调者发起事物,当所有的参与者回答"是",事务才会执行,即使有一个参与者发送"否",此事务也会放弃.
   2. 当收到所有的参与者"是"之后,协调者决定提交事务,这个决定具有**不可撤回性**,即使参与者发生了故障,也要一直重试直到成功为止.即一旦做出承诺,参与者必须执行.
   3. 当协调者故障,参与者检测到后会终止事务执行,如果已经应答"是",就只能 等待协调者再次发送命令,不会执行其他的动作.
5. 全序广播的作用:全序广播主要用来实现数据库复制 ：每条消息代表的是数据库写请求，然后按照相同的
   顺序在多个节点上应用写操作，从而达到多副本之间的一致性。  
6. 线性化,因果关系,一致性共识.

## 第三部分 派生数据

### 第十章 批处理系统

1. 批处理系统(离线系统):用户输入数据或规则后,需要等待任务的执行完成,任务执行不是时时的,可是需要几小时或者几天.
2. 如果作业的工作集大于可用内存,则排序方法的优点是可以高效的使用磁盘.数据块可以在内存中排序并作为段文件写入磁盘,然后多个排序的段可以合并为一个更大的排序文件.
3. MapReduce的工作原理是:读取一行记录,调用Mapper函数从每一个输入中提取一个键值对.对关键字所有的键值对进行排序.调用reduce函数遍历排序后的键值对.出现多次的关键字会排序到了一起.分布式中执行是将每个处理文件独立分块,不同节点将文件进行拷贝后进行处理.
4. 当执行设计少量记录的时候,用join进行查找.

### 第十一章 流处理系统

1. 与批处理系统的区别是:批处理系统认为输入是有界的,每次输入是确定的,等待计算完成即处理完了这次的任务,而流处理系统认为每时每刻数据都在变化和输入,输入是无界的.
2. 当消费者跟不上生产者速度的时候会有三种选择:丢弃消息,缓冲或应用背压.
3. 双重写入会造成并发问题,解决的办法的使用版本号,同时如果其中一个不成功还会有容错问题,需要保证他们的原子性.
4. 流处理长期以来被用于监控的目的:例如冻结银行卡.
5. 传统的搜索首先索引文档,然后在索引上进行查找,而流则是反过来,查询条件先保存下来,所有文档流过查询条件,可以对查询和文档都进行索引,从而缩小匹配的查询集合.elasticSearch就是流的处理方式.
6. 消息传递和RPC(Actor框架和流处理的区别)
   - Actor框架主要是管理通信模块的井发和分布式执行的机制，而流处理主要是数据管理技术。 
   - Actor之 间 的交流往往是短暂的，井且是一对一的，而事件日志是持久的、多用户的。  
   - Actor可以以任意方式进行通信（包括循环请求／响应模式），但流处理器通常设 置在非循环流水线中，其中每个流是一个特定作业的输出，并且从一组定义 明确的输入流派生而来。  
   - Actor就是之前碰见过的akka.
7. 时间延迟的验证办法:根据设备的时钟,记录事件发生的时间.根据设备时间,记录时间发送的时间,根据服务器的时间,记录收到的时间,时间差可以算出消息延时了多少时间.
8. 容错机制是使用微处理,将流时间分解成多个小的流,如果出现错误就返回到最近的流事件中.
9. 容错机制还包括保证事物的原子性和幂等性,kafka使用消息的偏移量来保证幂等,消息消费会比对当之前操作的消息的偏移量,避免重复操作.

### 第十二章 数据系统的未来

1. 全序处理的方法一般是将所有的从节点的数据都通过一个主节点进行排序,保证写入顺序的正确性,但是这样往往会使吞吐量限制在单个主节点的上线上,不过一般的系统都不会触及到上线.
2. 操作系统和数据库之间的异同:操作系统面向硬件,更加的底层.数据库是更加高级的语言,忽视底层问题,可以直接使用提供的函数.没有谁好谁坏.
3. web端的每一次重试都会看做是新的请求,数据库一会看做是新的事务,通常去重机制无法起到作用.解决的办法是可以为操作生成一个标识符.web重复提交,会有相同的标识符.
4. 强制约束
   1. 唯一性约束:每次请求生成一个表示,就是唯一性约束的一种,但是唯一性需要达成共识,一般的方法是将单一节点作为主节点,并负责所有的决定.
   2. 多分区请求处理:例如一个包含请求id,一个包含收款人账户,另一个包含付款人账户.不必把他们放在同一个分区,而是包含请求id追加到对应的日志分区,对于每个请求消息,它发送两条输出消息,第一个到收款人账户,另一个到付款人账户.由日志分区来确保提交事务的唯一性.
